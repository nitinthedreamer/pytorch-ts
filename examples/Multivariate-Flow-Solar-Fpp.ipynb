{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.multivariate_grouper import MultivariateGrouper\n",
    "from gluonts.dataset.repository.datasets import dataset_recipes, get_dataset\n",
    "from pts.model.tempflow import TempFlowEstimator\n",
    "from pts.model.transformer_tempflow import TransformerTempFlowEstimator\n",
    "from pts import Trainer\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import MultivariateEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepeare data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(\"solar_nips\", regenerate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetaData(freq='H', target=None, feat_static_cat=[CategoricalFeatureInfo(name='feat_static_cat', cardinality='137')], feat_static_real=[], feat_dynamic_real=[], feat_dynamic_cat=[], prediction_length=24)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grouper = MultivariateGrouper(max_target_dim=int(dataset.metadata.feat_static_cat[0].cardinality))\n",
    "\n",
    "test_grouper = MultivariateGrouper(num_test_dates=int(len(dataset.test)/len(dataset.train)), \n",
    "                                   max_target_dim=int(dataset.metadata.feat_static_cat[0].cardinality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nitinkumar/opt/anaconda3/lib/python3.8/site-packages/gluonts/dataset/multivariate_grouper.py:182: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return {FieldName.TARGET: np.array([funcs(data) for data in dataset])}\n"
     ]
    }
   ],
   "source": [
    "dataset_train = train_grouper(dataset.train)\n",
    "dataset_test = test_grouper(dataset.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MultivariateEvaluator(quantiles=(np.arange(20)/20.0)[1:],\n",
    "                                  target_agg_funcs={'sum': np.sum})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `GRU-Real-NVP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TempFlowEstimator(\n",
    "    target_dim=int(dataset.metadata.feat_static_cat[0].cardinality),\n",
    "    prediction_length=dataset.metadata.prediction_length,\n",
    "    cell_type='GRU',\n",
    "    input_size='552',\n",
    "    freq=dataset.metadata.freq,\n",
    "    scaling=True,\n",
    "    dequantize=True,\n",
    "    n_blocks=4,\n",
    "    trainer=Trainer(device=device,\n",
    "                    epochs=45,\n",
    "                    learning_rate=1e-3,\n",
    "                    num_batches_per_epoch=100,\n",
    "                    batch_size=64)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'input_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8c6cf609773e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m forecast_it, ts_it = make_evaluation_predictions(dataset=dataset_test,\n\u001b[1;32m      3\u001b[0m                                              \u001b[0mpredictor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                              num_samples=100)\n\u001b[1;32m      5\u001b[0m \u001b[0mforecasts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforecast_it\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/pytorch-ts-master/pts/model/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, training_data, validation_data, num_workers, prefetch_factor, shuffle_buffer_length, cache_data, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     ) -> PyTorchPredictor:\n\u001b[0;32m--> 179\u001b[0;31m         return self.train_model(\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/pytorch-ts-master/pts/model/estimator.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, training_data, validation_data, num_workers, prefetch_factor, shuffle_buffer_length, cache_data, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mtransformation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_transformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mtrained_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0minput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_module_forward_input_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/pytorch-ts-master/pts/model/tempflow/tempflow_estimator.py\u001b[0m in \u001b[0;36mcreate_training_network\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_training_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTempFlowTrainingNetwork\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         return TempFlowTrainingNetwork(\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mtarget_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/gluonts/core/component.py\u001b[0m in \u001b[0;36minit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidated_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;31m# attach the Pydantic model as the attribute of the initializer wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/pytorch-ts-master/pts/model/tempflow/tempflow_network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_size, num_layers, num_cells, cell_type, history_length, context_length, prediction_length, dropout_rate, lags_seq, target_dim, conditioning_length, flow_type, n_blocks, hidden_size, n_hidden, dequantize, cardinality, embedding_dimension, scaling, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         }[flow_type]\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         self.flow = flow_cls(\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mn_blocks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_blocks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'input_size'"
     ]
    }
   ],
   "source": [
    "predictor = estimator.train(dataset_train)\n",
    "forecast_it, ts_it = make_evaluation_predictions(dataset=dataset_test,\n",
    "                                             predictor=predictor,\n",
    "                                             num_samples=100)\n",
    "forecasts = list(forecast_it)\n",
    "targets = list(ts_it)\n",
    "\n",
    "agg_metric, _ = evaluator(targets, forecasts, num_series=len(dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CRPS: {}\".format(agg_metric['mean_wQuantileLoss']))\n",
    "print(\"ND: {}\".format(agg_metric['ND']))\n",
    "print(\"NRMSE: {}\".format(agg_metric['NRMSE']))\n",
    "print(\"MSE: {}\".format(agg_metric['MSE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CRPS-Sum: {}\".format(agg_metric['m_sum_mean_wQuantileLoss']))\n",
    "print(\"ND-Sum: {}\".format(agg_metric['m_sum_ND']))\n",
    "print(\"NRMSE-Sum: {}\".format(agg_metric['m_sum_NRMSE']))\n",
    "print(\"MSE-Sum: {}\".format(agg_metric['m_sum_MSE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `GRU-MAF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TempFlowEstimator(\n",
    "    target_dim=int(dataset.metadata.feat_static_cat[0].cardinality),\n",
    "    prediction_length=dataset.metadata.prediction_length,\n",
    "    cell_type='GRU',\n",
    "    input_size=552,\n",
    "    freq=dataset.metadata.freq,\n",
    "    scaling=True,\n",
    "    dequantize=True,\n",
    "    flow_type='MAF',\n",
    "    trainer=Trainer(device=device,\n",
    "                    epochs=25,\n",
    "                    learning_rate=1e-3,\n",
    "                    num_batches_per_epoch=100,\n",
    "                    batch_size=64)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.train(dataset_train)\n",
    "forecast_it, ts_it = make_evaluation_predictions(dataset=dataset_test,\n",
    "                                             predictor=predictor,\n",
    "                                             num_samples=100)\n",
    "forecasts = list(forecast_it)\n",
    "targets = list(ts_it)\n",
    "\n",
    "agg_metric, _ = evaluator(targets, forecasts, num_series=len(dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CRPS: {}\".format(agg_metric['mean_wQuantileLoss']))\n",
    "print(\"ND: {}\".format(agg_metric['ND']))\n",
    "print(\"NRMSE: {}\".format(agg_metric['NRMSE']))\n",
    "print(\"MSE: {}\".format(agg_metric['MSE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CRPS-Sum: {}\".format(agg_metric['m_sum_mean_wQuantileLoss']))\n",
    "print(\"ND-Sum: {}\".format(agg_metric['m_sum_ND']))\n",
    "print(\"NRMSE-Sum: {}\".format(agg_metric['m_sum_NRMSE']))\n",
    "print(\"MSE-Sum: {}\".format(agg_metric['m_sum_MSE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Transformer-MAF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TransformerTempFlowEstimator(\n",
    "    d_model=16,\n",
    "    num_heads=4,\n",
    "    input_size=552,\n",
    "    target_dim=int(dataset.metadata.feat_static_cat[0].cardinality),\n",
    "    prediction_length=dataset.metadata.prediction_length,\n",
    "    context_length=dataset.metadata.prediction_length*4,\n",
    "    flow_type='MAF',\n",
    "    dequantize=True,\n",
    "    freq=dataset.metadata.freq,\n",
    "    trainer=Trainer(\n",
    "        device=device,\n",
    "        epochs=14,\n",
    "        learning_rate=1e-3,\n",
    "        num_batches_per_epoch=100,\n",
    "        batch_size=64,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.train(dataset_train)\n",
    "forecast_it, ts_it = make_evaluation_predictions(dataset=dataset_test,\n",
    "                                             predictor=predictor,\n",
    "                                             num_samples=100)\n",
    "forecasts = list(forecast_it)\n",
    "targets = list(ts_it)\n",
    "\n",
    "agg_metric, _ = evaluator(targets, forecasts, num_series=len(dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CRPS: {}\".format(agg_metric['mean_wQuantileLoss']))\n",
    "print(\"ND: {}\".format(agg_metric['ND']))\n",
    "print(\"NRMSE: {}\".format(agg_metric['NRMSE']))\n",
    "print(\"MSE: {}\".format(agg_metric['MSE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CRPS-Sum: {}\".format(agg_metric['m_sum_mean_wQuantileLoss']))\n",
    "print(\"ND-Sum: {}\".format(agg_metric['m_sum_ND']))\n",
    "print(\"NRMSE-Sum: {}\".format(agg_metric['m_sum_NRMSE']))\n",
    "print(\"MSE-Sum: {}\".format(agg_metric['m_sum_MSE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
